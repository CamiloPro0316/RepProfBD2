Rodrigo Nunez, Quiz #9 cluster ejemplo de mongo
--------------------------------------------------------

Existe una empresa internacional en latam que se llama disponibles.com que es un tipo de gig economy (uber), donde se inscriben multiples servicios como por ejemplo plomería, soldadura, peluquería, cuido de mascotas, etc donde las personas ofrecen dichos servicios en ciertas zonas geográficas a un precio por hora. La empresa disponibles.com opera en costa rica, panamá, nicaragua y honduras actualmente se espera que puedan expandirse a otros países en el futuro.
Es importante para la empresa tener una disponibilidad de 99.99, que no existan "single point of failures" y lo otro importante es que las personas y servicios son regionalizados por país, por temas de idioma, cultura y moneda. Entonces es necesario crear un modelo distribuido del sistema. 


// crear la red
docker network create --driver bridge --subnet 10.0.0.0/27 disponet

// iniciar un servidor de configuración en modo configserver indicando la red y el nombre del replica set que dichos servidores van a atender
// lo ideal es agregar mas servidores de configuracion en la replica
docker run -d --net disponet --ip 10.0.0.4 --name dispconf1 mongo mongod --port 27017 --configsvr --replSet "repconfdisp" --dbpath /data/configdb
docker run -d --net disponet --ip 10.0.0.5 --name dispconf2 mongo mongod --port 27017 --configsvr --replSet "repconfdisp" --dbpath /data/configdb 

// ingresamos a un servidor de configuracion, y solo a uno, cualquiera de los servers de la misma replica
docker exec -it dispconf1 bash

// hacerle init al servicio de replica set para que haya replicacion entre los servidores de configuracion
// ojo que este rs es un comando de mongo, entonces se ejecuta dentro de mongo, rs => replicaset
rs.initiate(
  {
    _id: "repconfdisp",
    configsvr: true,
    members: [
      { _id : 0, host : "10.0.0.4:27017" },
      { _id : 1, host : "10.0.0.5:27017" }
    ]
  }
);

// revisar instruccion rs.slaveOk() 
// ejecutar rs.status() // me entrega estadisticas del estado de la replicacion


// inicializo shards y asignarlos a una replica, replica que aun no está activa pero se declara cual es

docker run -d --net mongonet --ip 10.14.1.20 --name data_sj1 mongo mongod --port 27017 --shardsvr --replSet "repSanjose"
docker run -d --net mongonet --ip 10.14.1.22 --name data_sj2 mongo mongod --port 27017 --shardsvr --replSet "repSanjose"
docker run -d --net mongonet --ip 10.14.1.21 --name data_limon1 mongo mongod --port 27017 --shardsvr --replSet "repLimon"
docker run -d --net mongonet --ip 10.14.1.23 --name data_limon2 mongo mongod --port 27017 --shardsvr --replSet "repLimon"

// conectarse a uno de los servidores e inicializar la replica entre ellos
// me conecto a un shardserver que sea miembro de la repSanjose para inicializar la rep
rs.initiate(
  {
    _id : "repSanjose",
    members: [
      { _id : 0, host : "10.14.1.20:27017" },
      { _id : 1, host : "10.14.1.22:27017" }
    ]
  }
)

// me conecto a un shardserver que sea miembro de la repLimon para inicializar la rep
rs.initiate(
  {
    _id : "repLimon",
    members: [
      { _id : 0, host : "10.14.1.21:27017" },
      { _id : 1, host : "10.14.1.23:27017" }
    ]
  }
)


// vamos a inicializar el router indicando cuales son los servidores de configuracion
docker run -d -p 27017:27017 --net mongonet --ip 10.14.1.24 --name tecmongo mongo mongos --port 27017 --configdb repconfigtec/10.14.1.18:27017,10.14.1.19:27017

// conectamos al router

sh.addShard( "repSanjose/10.14.1.20:27017");  hacemos shards con un server en cada replica, no hace faltan los otros porque ya estan en replica entre si
sh.addShard( "repLimon/10.14.1.21:27017");

sh.status();

// para el sistema de voting es mejor agregar un arbitro

docker run -d --net mongonet --ip 10.14.1.26 --name poveda mongo mongod --port 27017 --replSet repSanjose
docker run -d --net mongonet --ip 10.14.1.27 --name bejarano mongo mongod --port 27017 --replSet repLimon

// me conecto a cada servidor de replica y le agrego su arbitro
agrego arbitro en el primario de la replica de sanjose
rs.addArb("10.14.1.26:27017")

agrego arbitro en el primario de la replica de limon
rs.addArb("10.14.1.27:27017")

ya tenemos las replicas listas, el router ya se le dijo cuales son los shardservers
procedemos a configurar la distribucion de datos del shard

conectarnos al router y probamos

// hagan esta parte de distribuir por configuracion los cursos que son de una sede u otra
// para hacer distribucion manual de datos se puede hacer por shardkeys de rangos o con shard tags
// desde el router
sh.addShardTag("repSanjose", "SJ")
sh.addShardTag("repLimon", "Lemon")

sh.addTagRange( "matricula.cursos",
                { sede: "Limon"},
                { sede: "Limon2"},
                "Lemon"
              )

sh.addTagRange( "matricula.cursos",
                { sede: "San Jose"},
                { sede: "San Jose2"},
                "SJ"
              )




//rs.remove("x.x.x.x:27024")

// Indico cual va a ser la base de datos que va a soportar sharding
sh.enableSharding("matricula");

// luego el collection y el campo del collection que va servir como shardkey
sh.shardCollection("matricula.profesores", { nombre : "hashed" } )

sh.status();



// con eso terminado ya puedo probar el sharding y la replica que funcionan correctamente

-------------------
docker start cfgtec01
docker start cfgtec02
docker start data_limon2
docker start data_limon1
docker start data_sj2
docker start data_sj1
docker start poveda 
docker start bejarano
docker start tecmongo


docker stop tecmongo
docker stop data_limon2
docker stop data_limon1
docker stop data_sj2
docker stop data_sj1
docker stop poveda 
docker stop bejarano

docker stop dispconf1
docker stop dispconf2
